import pdb
import numpy as np
from tqdm.auto import tqdm
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import torchvision.transforms as transforms
from torchvision import datasets
from torchvision.utils import make_grid
from torchvision.datasets import FashionMNIST

transform = transforms.Compose([
    transforms.Resize(512),  # Ensure image dimensions match expected input
    transforms.CenterCrop(512),
    transforms.ToTensor()
])
dataset = FashionMNIST(root='data', download=True, transform=transform)

epoch = 1000
cur_iter = 0
info_iter = 300
mean_gen_loss = 0
mean_disc_loss = 0

z_dim = 64
lr = 0.0002
loss = nn.BCEWithLogitsLoss()
batch_size = 1024
device = "cuda" if torch.cuda.is_available() else "cpu"

def genBlock(inp_nodes, out_nodes):
    return nn.Sequential(
        nn.Linear(inp_nodes, out_nodes),
        nn.BatchNorm1d(out_nodes),
        nn.ReLU()
    )

class Generator(nn.Module):
    def __init__(self, z_dim, img_dim):
        super().__init__()
        self.gen = nn.Sequential(
            genBlock(z_dim, 256),
            genBlock(256, 512),
            genBlock(512, 1024),
            nn.Linear(1024, img_dim),
            nn.Tanh() 
        )

    def forward(self, noise):
        return self.gen(noise)

dataloader = DataLoader( dataset=dataset, batch_size=batch_size, shuffle=True)

def genBlock(inp_nodes, out_nodes):  
    return nn.Sequential(
        nn.Linear(inp_nodes, out_nodes),
        nn.BatchNorm1d(out_nodes),
        nn.ReLU()
    )

def gen_noise(batch_size, z_dim) :
    return torch.randn(batch_size, z_dim).to(device)

class Generator(nn.Module):
    def __init__(self, z_dim =64, o_dim =512 * 512 * 3, h_dim =120):
        super().__init__()
        self.gen = nn.Sequential(
            genBlock(z_dim, h_dim),
            genBlock(h_dim, h_dim * 2),
            genBlock(h_dim * 2, h_dim * 4),
            genBlock(h_dim * 4, h_dim * 8),
            nn.Linear(h_dim * 8, o_dim),
            nn.Sigmoid(),
        )

    def forward(self, noise):
        return  self.gen(noise)

def discBlock(inp_nodes, out_nodes):
    return nn.Sequential(
        nn.Linear(inp_nodes, out_nodes),
        nn.LeakyReLU(0.2)
    )

class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.disc = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=4 , stride=2, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, 1, kernel_size=4, stride=1, padding=0),
        )

    def forward(self, image):
        return self.disc(image).view(-1)

gen= Generator(z_dim).to(device)
disc = Discriminator().to(device)

gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)
disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)

def gen_loss(loss_func, gen, disc, batch_size, z_dim):
    noise = gen_noise(batch_size, z_dim)
    fake = gen(noise)
    pred  = disc(fake)
    target = torch.ones_like(pred)
    return loss_func(pred, target)

def disc_loss(loss_func, gen, disc, batch_size, z_dim, real):
    noise = gen_noise(batch_size, z_dim)
    fake = gen(noise)
    disc_fake = disc(fake.detach())
    disc_fake_target = torch.zeros_like(disc_fake)
    disc_fake_loss = loss_func(disc_fake, disc_fake_target)

    disc_real = disc(real)
    disc_real_target = torch.ones_like(disc_real)
    disc_real_loss = loss_func(disc_real, disc_real_target)

    return (disc_fake_loss + disc_real_loss) / 2

for epoch in range(epoch):
    mean_disc_loss_list = [ ]
    mean_gen_loss_list = [ ]
    iters_list =  [ ]

    for real_image, _ in tqdm(dataloader):
        disc_opt.zero_grad()
        cur_batch_size = len(real_image)

        real_image = real_image.to(device) 
        disc_losses = disc_loss(loss, gen, disc, cur_batch_size, z_dim, real_image)
        disc_losses.backward()
        disc_opt.step()

        gen_opt.zero_grad()
        gen_losses = gen_loss(loss, gen, disc, cur_batch_size, z_dim)
        gen_losses.backward()
        gen_opt.step()

        mean_disc_loss += disc_losses.item() / info_iter
        mean_gen_loss += gen_losses.item() / info_iter
        mean_disc_loss_list.append(mean_disc_loss)
        mean_gen_loss_list.append(mean_gen_loss)

        if cur_iter % info_iter == 0 and cur_iter > 0:
            fake_noise = gen_noise(cur_batch_size, z_dim)
            fake = gen(fake_noise)
            show(real_image)
            show(fake)
            print(f"{epoch} : step {cur_iter}, Generator loss : {mean_gen_loss}, Discriminator Loss : {mean_disc_loss}")
            mean_gen_loss, mean_disc_loss = 0, 0
        iters_list.append(cur_iter)
        cur_iter += 1

import os

gen.eval()
num_images = 16  # Number of images to generate
output_dir = "./fashion_mnist_generated_images/" 
os.makedirs(output_dir, exist_ok=True)

with torch.no_grad():

    noise = gen_noise(num_images, z_dim)
    fake_images = gen(noise).view(-1, 3, 512, 512).cpu()
    for i, img in enumerate(fake_images):
        save_path = os.path.join(output_dir, f"generated_image_{i + 1}.png")
        plt.imsave(save_path, img.permute(1, 2, 0).numpy())
        print(f"Image saved to {save_path}")

grid = make_grid(fake_images, nrow=4).permute(1, 2, 0).numpy()
plt.figure(figsize=(10, 10))
plt.imshow(grid)
plt.axis("off")
plt.show()
